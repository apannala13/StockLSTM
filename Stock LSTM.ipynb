{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a56c1b1-55c7-47e2-9091-676a2c24a983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install psycopg2-binary\n",
    "# !pip install yfinance\n",
    "# !pip install torch\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19d93bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "import psycopg2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2267892d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stock_ingestion(ticker_list):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=1825)\n",
    "    \n",
    "    stock_data = {}\n",
    "    \n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            hist_data = stock.history(\n",
    "                start=start_date.strftime('%Y-%m-%d'),\n",
    "                end=end_date.strftime('%Y-%m-%d'),\n",
    "                interval='1d'\n",
    "            )\n",
    "            hist_data['Ticker'] = ticker\n",
    "            \n",
    "            stock_data[ticker] = hist_data\n",
    "        except Exception as e:\n",
    "            print(f'could not rertieve info for {ticker}: {str(e)}')\n",
    "    \n",
    "    combined_data = pd.concat(stock_data.values())\n",
    "    combined_data.reset_index(inplace=True)\n",
    "    combined_data = combined_data[['Ticker', 'Date'] + [col for col in combined_data.columns if col not in ['Ticker', 'Date']]]\n",
    "    \n",
    "    \n",
    "    return combined_data\n",
    "    \n",
    "ticker_list = ['MSFT', 'AAPL', 'GOOGL', 'AMZN', 'META', 'NVDA', 'TSLA', 'JPM', 'V', 'MA', 'BAC', \n",
    "               'GS', 'JNJ', 'UNH', 'PFE', 'ABBV', 'WMT', 'PG','KO', 'PEP', 'CAT', 'BA', 'HON', 'DIS', \n",
    "               'NFLX', 'INTC', 'AMD', 'QCOM', 'XOM', 'CVX']\n",
    "stock_data = stock_ingestion(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6dd4da4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37710 entries, 0 to 37709\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype                           \n",
      "---  ------        --------------  -----                           \n",
      " 0   Ticker        37710 non-null  object                          \n",
      " 1   Date          37710 non-null  datetime64[ns, America/New_York]\n",
      " 2   Open          37710 non-null  float64                         \n",
      " 3   High          37710 non-null  float64                         \n",
      " 4   Low           37710 non-null  float64                         \n",
      " 5   Close         37710 non-null  float64                         \n",
      " 6   Volume        37710 non-null  int64                           \n",
      " 7   Dividends     37710 non-null  float64                         \n",
      " 8   Stock Splits  37710 non-null  float64                         \n",
      " 9   year          37710 non-null  int32                           \n",
      " 10  month         37710 non-null  int32                           \n",
      " 11  day           37710 non-null  int32                           \n",
      " 12  day_of_week   37710 non-null  int32                           \n",
      "dtypes: datetime64[ns, America/New_York](1), float64(6), int32(4), int64(1), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "stock_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3838c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37710, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df144276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37710.000000</td>\n",
       "      <td>37710.000000</td>\n",
       "      <td>37710.000000</td>\n",
       "      <td>37710.000000</td>\n",
       "      <td>3.771000e+04</td>\n",
       "      <td>37710.000000</td>\n",
       "      <td>37710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>168.698106</td>\n",
       "      <td>170.687184</td>\n",
       "      <td>166.687501</td>\n",
       "      <td>168.720364</td>\n",
       "      <td>3.936483e+07</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>124.412268</td>\n",
       "      <td>125.785261</td>\n",
       "      <td>123.017337</td>\n",
       "      <td>124.427389</td>\n",
       "      <td>9.082301e+07</td>\n",
       "      <td>0.104442</td>\n",
       "      <td>0.160879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.984939</td>\n",
       "      <td>5.174166</td>\n",
       "      <td>4.501143</td>\n",
       "      <td>4.892763</td>\n",
       "      <td>4.601000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>79.991919</td>\n",
       "      <td>80.953674</td>\n",
       "      <td>78.862120</td>\n",
       "      <td>79.878531</td>\n",
       "      <td>5.450325e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>144.849906</td>\n",
       "      <td>146.307168</td>\n",
       "      <td>143.279384</td>\n",
       "      <td>144.765503</td>\n",
       "      <td>1.238540e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>208.986257</td>\n",
       "      <td>211.448502</td>\n",
       "      <td>206.471741</td>\n",
       "      <td>209.126301</td>\n",
       "      <td>3.390808e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>833.669983</td>\n",
       "      <td>841.000000</td>\n",
       "      <td>830.020020</td>\n",
       "      <td>837.260010</td>\n",
       "      <td>1.543911e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close        Volume  \\\n",
       "count  37710.000000  37710.000000  37710.000000  37710.000000  3.771000e+04   \n",
       "mean     168.698106    170.687184    166.687501    168.720364  3.936483e+07   \n",
       "std      124.412268    125.785261    123.017337    124.427389  9.082301e+07   \n",
       "min        4.984939      5.174166      4.501143      4.892763  4.601000e+05   \n",
       "25%       79.991919     80.953674     78.862120     79.878531  5.450325e+06   \n",
       "50%      144.849906    146.307168    143.279384    144.765503  1.238540e+07   \n",
       "75%      208.986257    211.448502    206.471741    209.126301  3.390808e+07   \n",
       "max      833.669983    841.000000    830.020020    837.260010  1.543911e+09   \n",
       "\n",
       "          Dividends  Stock Splits  \n",
       "count  37710.000000  37710.000000  \n",
       "mean       0.009442      0.001858  \n",
       "std        0.104442      0.160879  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        3.000000     20.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e843259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37710\n"
     ]
    }
   ],
   "source": [
    "print(len(stock_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "412a49e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.892763137817383\n",
      "837.260009765625\n"
     ]
    }
   ],
   "source": [
    "print(stock_data['Close'].min())\n",
    "print(stock_data['Close'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a619a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_preprocessing(df, sequence_length=10, test_size=0.3):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day \n",
    "    df['day_of_week'] = df['Date'].dt.dayofweek \n",
    "    \n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Volume', \n",
    "               'year', 'month', 'day', 'day_of_week']\n",
    "    data = df[features].values\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(data_scaled) - sequence_length):\n",
    "        X.append(data_scaled[i:(i + sequence_length)])\n",
    "        y.append(data_scaled[i + sequence_length, 3]) #3 = index for close price (dependent variable)\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * (1 - test_size))\n",
    "    \n",
    "    X_train = X[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    y_train = y[:train_size]\n",
    "    y_test = y[train_size:]\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "    \n",
    "    dataset_train = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    dataloader_train = DataLoader(dataset=dataset, batch_size=32, \n",
    "                            shuffle=True, pin_memory=torch.cuda.is_available)\n",
    "    \n",
    "    dataset_test = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    dataloader_test = DataLoader(dataset=dataset, batch_size=32, \n",
    "                                shuffle=True, pin_memory=torch.cuda.is_available)\n",
    "\n",
    "    return dataloader_train, dataloader_test\n",
    "\n",
    "dataloader_train, dataloader_test = temporal_preprocessing(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b623d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0635\n",
      "Epoch 2/20, Loss: 0.0482\n",
      "Epoch 3/20, Loss: 0.0385\n",
      "Epoch 4/20, Loss: 0.0323\n",
      "Epoch 5/20, Loss: 0.0285\n",
      "Epoch 6/20, Loss: 0.0260\n",
      "Epoch 7/20, Loss: 0.0244\n",
      "Epoch 8/20, Loss: 0.0234\n",
      "Epoch 9/20, Loss: 0.0228\n",
      "Epoch 10/20, Loss: 0.0224\n",
      "Epoch 11/20, Loss: 0.0222\n",
      "Epoch 12/20, Loss: 0.0220\n",
      "Epoch 13/20, Loss: 0.0219\n",
      "Epoch 14/20, Loss: 0.0219\n",
      "Epoch 15/20, Loss: 0.0218\n",
      "Epoch 16/20, Loss: 0.0218\n",
      "Epoch 17/20, Loss: 0.0218\n",
      "Epoch 18/20, Loss: 0.0218\n",
      "Epoch 19/20, Loss: 0.0218\n",
      "Epoch 20/20, Loss: 0.0218\n",
      "4.237044861582323\n"
     ]
    }
   ],
   "source": [
    "input_size = 9 #num features \n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True, \n",
    "                            dropout=0.2\n",
    "                           )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #initialize hidden and cell states with zeroes\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out \n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers)\n",
    "floss = nn.MSELoss()\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.0001, weight_decay=0)\n",
    "epochs = 20 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = floss(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    epoch_loss /= len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    \n",
    "model.eval()\n",
    "test_loss = 0 \n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in dataloader_test:\n",
    "        outputs = model(X_test)\n",
    "        loss = floss(outputs, y_test)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "rmse = np.sqrt(test_loss)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e60ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do: implement early stopping \n",
    "#push and consume data from postgres db \n",
    "#improve model - regularization, try better optimizers. likely adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d3e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41d0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c208e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f8d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4f78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803c42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243687d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178090bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0b9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86483461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc7e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
